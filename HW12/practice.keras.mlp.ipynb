{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Machine Learning\n",
    "##### https://keras.io/getting-started/sequential-model-guide/\n",
    "#### prepared by Chao-Lin Liu\n",
    "###### 目前這一個程式的辨識率很差\n",
    "###### 改變一下你的 sequential model 的設定，看看能不能達成比較高的辨識率？\n",
    "###### 能不能把辨識率提高到 90% 以上？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"introML2019.taskx.train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.03072</td>\n",
       "      <td>3.82764</td>\n",
       "      <td>0.58316</td>\n",
       "      <td>0.05098</td>\n",
       "      <td>2.33048</td>\n",
       "      <td>1.31349</td>\n",
       "      <td>0.83424</td>\n",
       "      <td>3.03314</td>\n",
       "      <td>0.94328</td>\n",
       "      <td>1.23016</td>\n",
       "      <td>0.24975</td>\n",
       "      <td>0.85205</td>\n",
       "      <td>0.34522</td>\n",
       "      <td>1.33981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.06554</td>\n",
       "      <td>2.58245</td>\n",
       "      <td>2.78158</td>\n",
       "      <td>2.64259</td>\n",
       "      <td>0.36718</td>\n",
       "      <td>0.72675</td>\n",
       "      <td>5.03764</td>\n",
       "      <td>2.74495</td>\n",
       "      <td>0.23774</td>\n",
       "      <td>0.50992</td>\n",
       "      <td>0.52516</td>\n",
       "      <td>0.08850</td>\n",
       "      <td>0.16748</td>\n",
       "      <td>1.71180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.79113</td>\n",
       "      <td>4.26817</td>\n",
       "      <td>3.31938</td>\n",
       "      <td>1.69178</td>\n",
       "      <td>0.60181</td>\n",
       "      <td>0.97848</td>\n",
       "      <td>2.77091</td>\n",
       "      <td>0.64957</td>\n",
       "      <td>0.15596</td>\n",
       "      <td>0.81251</td>\n",
       "      <td>0.47414</td>\n",
       "      <td>1.27370</td>\n",
       "      <td>1.66604</td>\n",
       "      <td>1.27203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.54282</td>\n",
       "      <td>0.70391</td>\n",
       "      <td>4.64737</td>\n",
       "      <td>2.79710</td>\n",
       "      <td>1.97160</td>\n",
       "      <td>0.72203</td>\n",
       "      <td>4.49158</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.91521</td>\n",
       "      <td>0.93423</td>\n",
       "      <td>0.31449</td>\n",
       "      <td>0.01357</td>\n",
       "      <td>0.78556</td>\n",
       "      <td>1.27886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.03771</td>\n",
       "      <td>2.79512</td>\n",
       "      <td>1.23405</td>\n",
       "      <td>0.43138</td>\n",
       "      <td>0.71433</td>\n",
       "      <td>0.77471</td>\n",
       "      <td>3.04295</td>\n",
       "      <td>1.22548</td>\n",
       "      <td>3.13544</td>\n",
       "      <td>0.38265</td>\n",
       "      <td>0.33434</td>\n",
       "      <td>1.14438</td>\n",
       "      <td>0.99043</td>\n",
       "      <td>1.28083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    3.03072    3.82764    0.58316    0.05098    2.33048    1.31349   \n",
       "1    2.06554    2.58245    2.78158    2.64259    0.36718    0.72675   \n",
       "2    4.79113    4.26817    3.31938    1.69178    0.60181    0.97848   \n",
       "3    0.54282    0.70391    4.64737    2.79710    1.97160    0.72203   \n",
       "4    3.03771    2.79512    1.23405    0.43138    0.71433    0.77471   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
       "0    0.83424    3.03314    0.94328    1.23016     0.24975     0.85205   \n",
       "1    5.03764    2.74495    0.23774    0.50992     0.52516     0.08850   \n",
       "2    2.77091    0.64957    0.15596    0.81251     0.47414     1.27370   \n",
       "3    4.49158    0.01500    0.91521    0.93423     0.31449     0.01357   \n",
       "4    3.04295    1.22548    3.13544    0.38265     0.33434     1.14438   \n",
       "\n",
       "   feature_12  feature_13  label  \n",
       "0     0.34522     1.33981      0  \n",
       "1     0.16748     1.71180      0  \n",
       "2     1.66604     1.27203      0  \n",
       "3     0.78556     1.27886      0  \n",
       "4     0.99043     1.28083      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df.iloc[:,0:14])\n",
    "y_train = np.array(df.iloc[:,14:15]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 以下的步驟在 Introduction to Machine learning 課程並沒有講到\n",
    "# 我們把 y 的數值變成了向量 － one-hot vector\n",
    "#\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_npy = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_npy = np_utils.to_categorical(encoded_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你可以試著增加 Dense 層的數目、或者改變個別 Dense 層的 nodes 數目、或者改變 activation functions\n",
    "#\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=14, activation='sigmoid'))\n",
    "    model.add(Dense(9, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model2 = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.6585 - acc: 0.1583\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.6327 - acc: 0.1689\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.6154 - acc: 0.2171\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.6042 - acc: 0.2506\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.5959 - acc: 0.2580\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.5880 - acc: 0.2653\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.5793 - acc: 0.2758\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.5686 - acc: 0.2944\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.5557 - acc: 0.3196\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.5412 - acc: 0.3320\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 0s 2us/step - loss: 1.5250 - acc: 0.3427\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 0s 2us/step - loss: 1.5066 - acc: 0.3588\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.4857 - acc: 0.3750\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.4624 - acc: 0.3943\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.4369 - acc: 0.4141\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.4103 - acc: 0.4306\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.3830 - acc: 0.4482\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.3560 - acc: 0.4641\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.3296 - acc: 0.4761\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 0s 3us/step - loss: 1.3041 - acc: 0.4848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f327e11bcc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在這裡，你可以嘗試增減 epochs 和 batch_size\n",
    "model2.fit(X_train , dummy_npy, epochs=20, batch_size=5000, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"introML2019.taskx.test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.array(df2.iloc[:,0:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicty = model2.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25848746, 0.20733264, 0.14432363, 0.1686158 , 0.22124049],\n",
       "       [0.23681776, 0.16600558, 0.18886667, 0.2138419 , 0.19446817],\n",
       "       [0.34597865, 0.18853168, 0.12200107, 0.11698179, 0.22650689],\n",
       "       [0.23070575, 0.1767936 , 0.17071044, 0.22797617, 0.19381398],\n",
       "       [0.17329623, 0.16133949, 0.28532833, 0.25694138, 0.12309461]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicty[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = np.array(df2.iloc[:,14:15]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicty = encoder.inverse_transform([np.argmax(item) for item in predicty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1501   18  201  160  620]\n",
      " [ 679  230  375 1007  209]\n",
      " [  97   16 1918  446   23]\n",
      " [ 384   41  681 1033  361]\n",
      " [ 685   23  113  187 1492]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(testy,predicty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.60      0.51      2500\n",
      "           1       0.70      0.09      0.16      2500\n",
      "           2       0.58      0.77      0.66      2500\n",
      "           3       0.36      0.41      0.39      2500\n",
      "           4       0.55      0.60      0.57      2500\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     12500\n",
      "   macro avg       0.53      0.49      0.46     12500\n",
      "weighted avg       0.53      0.49      0.46     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy,predicty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.5633 - acc: 0.2734\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.2305 - acc: 0.4679\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.0563 - acc: 0.5398\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.9720 - acc: 0.5710\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.9212 - acc: 0.5919\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.8816 - acc: 0.6081\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.8502 - acc: 0.6232\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.8278 - acc: 0.6349\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.8044 - acc: 0.6499\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.7862 - acc: 0.6594\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.7636 - acc: 0.6774\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.7412 - acc: 0.6900\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.7276 - acc: 0.7045\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.7047 - acc: 0.7216\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.6913 - acc: 0.7315\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.6690 - acc: 0.7442\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.6568 - acc: 0.7520\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.6482 - acc: 0.7588\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.6385 - acc: 0.7617\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.6302 - acc: 0.7641\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.6194 - acc: 0.7712\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.6122 - acc: 0.7764\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.6109 - acc: 0.7782\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.6011 - acc: 0.7799\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5982 - acc: 0.7831\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5962 - acc: 0.7833\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5910 - acc: 0.7875\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5867 - acc: 0.7895\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5814 - acc: 0.7937\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5785 - acc: 0.7934\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5725 - acc: 0.7938\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5686 - acc: 0.7977\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5629 - acc: 0.8020\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5641 - acc: 0.8008\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.5579 - acc: 0.8044\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5586 - acc: 0.8045\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5538 - acc: 0.8045\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5493 - acc: 0.8100\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5501 - acc: 0.8083\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5508 - acc: 0.8063\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5454 - acc: 0.8093\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5459 - acc: 0.8075\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5460 - acc: 0.8080\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5473 - acc: 0.8087\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5458 - acc: 0.8093\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5377 - acc: 0.8125\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5372 - acc: 0.8129\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5366 - acc: 0.8132\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5367 - acc: 0.8132\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5388 - acc: 0.8116\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5356 - acc: 0.8137\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5320 - acc: 0.8140\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5305 - acc: 0.8133\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5287 - acc: 0.8151\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5297 - acc: 0.8128\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5251 - acc: 0.8160\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5251 - acc: 0.8171\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5291 - acc: 0.8149\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5264 - acc: 0.8138\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5243 - acc: 0.8185\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5218 - acc: 0.8166\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5276 - acc: 0.8157\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5286 - acc: 0.8153\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5199 - acc: 0.8216\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4988 - acc: 0.8290\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4957 - acc: 0.8295\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4977 - acc: 0.8318\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.4968 - acc: 0.8295\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4979 - acc: 0.8305\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4931 - acc: 0.8329\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4941 - acc: 0.8332\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4929 - acc: 0.8324\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4928 - acc: 0.8314\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4881 - acc: 0.8348\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4988 - acc: 0.8311\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4984 - acc: 0.8299\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4941 - acc: 0.8321\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4932 - acc: 0.8339\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4938 - acc: 0.8331\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4941 - acc: 0.8314\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4938 - acc: 0.8348\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4938 - acc: 0.8324\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4965 - acc: 0.8325\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5049 - acc: 0.8286\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4950 - acc: 0.8331\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4884 - acc: 0.8348\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4868 - acc: 0.8355\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4957 - acc: 0.8330\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4963 - acc: 0.8319\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4864 - acc: 0.8370\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4932 - acc: 0.8324\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4895 - acc: 0.8340\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4865 - acc: 0.8377\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4915 - acc: 0.8328\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4936 - acc: 0.8346\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4904 - acc: 0.8337\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4941 - acc: 0.8350\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4896 - acc: 0.8358\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4874 - acc: 0.8353\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4872 - acc: 0.8334\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4860 - acc: 0.8362\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4900 - acc: 0.8350\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4878 - acc: 0.8358\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4856 - acc: 0.8354\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4872 - acc: 0.8368\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4823 - acc: 0.8386\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4782 - acc: 0.8408\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4834 - acc: 0.8382\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4900 - acc: 0.8356\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4795 - acc: 0.8370\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4877 - acc: 0.8345\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4881 - acc: 0.8343\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4874 - acc: 0.8326\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4901 - acc: 0.8349\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4910 - acc: 0.8352\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4854 - acc: 0.8367\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4823 - acc: 0.8365\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4904 - acc: 0.8356\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4871 - acc: 0.8354\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4802 - acc: 0.8360\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4915 - acc: 0.8338\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4796 - acc: 0.8377\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4844 - acc: 0.8366\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4815 - acc: 0.8395\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4862 - acc: 0.8375\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4795 - acc: 0.8380\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4830 - acc: 0.8369\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4895 - acc: 0.8351\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4850 - acc: 0.8365\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4824 - acc: 0.8386\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4863 - acc: 0.8362\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4867 - acc: 0.8362\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4814 - acc: 0.8370\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4866 - acc: 0.8356\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4850 - acc: 0.8382\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4809 - acc: 0.8387\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4765 - acc: 0.8388\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4841 - acc: 0.8355\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4814 - acc: 0.8377\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4866 - acc: 0.8361\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4878 - acc: 0.8368\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4853 - acc: 0.8356\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4850 - acc: 0.8371\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4756 - acc: 0.8400\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4766 - acc: 0.8377\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4702 - acc: 0.8426\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4806 - acc: 0.8378\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4794 - acc: 0.8381\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4776 - acc: 0.8397\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4778 - acc: 0.8390\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4747 - acc: 0.8409\n",
      "[[1580    1  254   14  651]\n",
      " [   0 2495    1    3    1]\n",
      " [   0   11 2322  127   40]\n",
      " [   0   25   10 2465    0]\n",
      " [   1    1  307   24 2167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.77      2500\n",
      "           1       0.98      1.00      0.99      2500\n",
      "           2       0.80      0.93      0.86      2500\n",
      "           3       0.94      0.99      0.96      2500\n",
      "           4       0.76      0.87      0.81      2500\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     12500\n",
      "   macro avg       0.90      0.88      0.88     12500\n",
      "weighted avg       0.90      0.88      0.88     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=14, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 在這裡，你可以嘗試增減 epochs 和 batch_size\n",
    "#model.fit(X_train , dummy_npy, epochs=200, batch_size=5000, verbose=1, shuffle=True)\n",
    "model.fit(X_train, dummy_npy,\n",
    "          batch_size=200,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          shuffle=True)\n",
    "\n",
    "predicty = model.predict(testX)\n",
    "predicty = encoder.inverse_transform([np.argmax(item) for item in predicty])\n",
    "print(confusion_matrix(testy,predicty))\n",
    "print(classification_report(testy,predicty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 3s 62us/step - loss: 0.9574 - acc: 0.5846\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4860 - acc: 0.8078\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3692 - acc: 0.8544\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3062 - acc: 0.8854\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2752 - acc: 0.9007\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2546 - acc: 0.9116\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2407 - acc: 0.9180\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2339 - acc: 0.9204\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2257 - acc: 0.9249\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2219 - acc: 0.9268\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2171 - acc: 0.9295\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.2120 - acc: 0.9307\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2118 - acc: 0.9305\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2064 - acc: 0.9333\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2047 - acc: 0.9352\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.2027 - acc: 0.9361\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.2006 - acc: 0.9361\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1972 - acc: 0.9383\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1959 - acc: 0.9373\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1937 - acc: 0.9390\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1911 - acc: 0.9392\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1924 - acc: 0.9394\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1871 - acc: 0.9411\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1866 - acc: 0.9411\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1829 - acc: 0.9427\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1828 - acc: 0.9418\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1792 - acc: 0.9435\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1803 - acc: 0.9432\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1746 - acc: 0.9458\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1732 - acc: 0.9455\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1715 - acc: 0.9462\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1677 - acc: 0.9470\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1652 - acc: 0.9479\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1638 - acc: 0.9482\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1595 - acc: 0.9499\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1569 - acc: 0.9504\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1548 - acc: 0.9517\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1528 - acc: 0.9510\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.1498 - acc: 0.9529\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1479 - acc: 0.9529\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1451 - acc: 0.9539\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1429 - acc: 0.9546\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1413 - acc: 0.9552\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.1362 - acc: 0.9562\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1343 - acc: 0.9567\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1348 - acc: 0.9565\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1330 - acc: 0.9573\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1303 - acc: 0.9583\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1283 - acc: 0.9593\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1266 - acc: 0.9598\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1290 - acc: 0.9583\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1252 - acc: 0.9596\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1237 - acc: 0.9608\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1196 - acc: 0.9622\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1205 - acc: 0.9615\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1174 - acc: 0.9626\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1188 - acc: 0.9624\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.1163 - acc: 0.9631\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1188 - acc: 0.9629\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1144 - acc: 0.9635\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1128 - acc: 0.9637\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1107 - acc: 0.9647\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1102 - acc: 0.9645\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.1101 - acc: 0.9648\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1118 - acc: 0.9646\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.1093 - acc: 0.9654\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1068 - acc: 0.9661\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.1092 - acc: 0.9651\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.1065 - acc: 0.9659\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.1072 - acc: 0.9657\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.1052 - acc: 0.9666\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.1065 - acc: 0.9664\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.1017 - acc: 0.9685\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.1008 - acc: 0.9682\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.1018 - acc: 0.9676\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.1042 - acc: 0.9667\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.1021 - acc: 0.9674\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.1019 - acc: 0.9675\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.1002 - acc: 0.9681\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0974 - acc: 0.9694\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.1000 - acc: 0.9683\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0970 - acc: 0.9696\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0993 - acc: 0.9685\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0979 - acc: 0.9692\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0952 - acc: 0.9701\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0950 - acc: 0.9703\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0964 - acc: 0.9699\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0944 - acc: 0.9705\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0958 - acc: 0.9697\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0948 - acc: 0.9703\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0952 - acc: 0.9696\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0944 - acc: 0.9702\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0908 - acc: 0.9714\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0918 - acc: 0.9710\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0947 - acc: 0.9698\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0916 - acc: 0.9710\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0920 - acc: 0.9706\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0919 - acc: 0.9706\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0889 - acc: 0.9711\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0915 - acc: 0.9710\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0893 - acc: 0.9715\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0925 - acc: 0.9706\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0892 - acc: 0.9718\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0921 - acc: 0.9698\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0869 - acc: 0.9722\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0871 - acc: 0.9727\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0862 - acc: 0.9721\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0853 - acc: 0.9725\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0846 - acc: 0.9727\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0850 - acc: 0.9731\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0860 - acc: 0.9726\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0861 - acc: 0.9723\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0837 - acc: 0.9730\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0841 - acc: 0.9732\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0840 - acc: 0.9730\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0824 - acc: 0.9732\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0838 - acc: 0.9725\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0812 - acc: 0.9736\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0860 - acc: 0.9722\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0805 - acc: 0.9743\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0801 - acc: 0.9742\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0792 - acc: 0.9746\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0801 - acc: 0.9739\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0805 - acc: 0.9743\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0805 - acc: 0.9738\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0784 - acc: 0.9742\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0783 - acc: 0.9744\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0785 - acc: 0.9743\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0774 - acc: 0.9749\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0757 - acc: 0.9757\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0773 - acc: 0.9746\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0768 - acc: 0.9750\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0746 - acc: 0.9755\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0744 - acc: 0.9758\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0749 - acc: 0.9760\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0734 - acc: 0.9763\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0708 - acc: 0.9771\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0721 - acc: 0.9761\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0742 - acc: 0.9759\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0739 - acc: 0.9760\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0717 - acc: 0.9769\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0719 - acc: 0.9769\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0687 - acc: 0.9778\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0701 - acc: 0.9775\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0712 - acc: 0.9772\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0694 - acc: 0.9779\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0686 - acc: 0.9783\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0686 - acc: 0.9781\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0689 - acc: 0.9778\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0675 - acc: 0.9782\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0678 - acc: 0.9782\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0669 - acc: 0.9785\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0665 - acc: 0.9784\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0668 - acc: 0.9786\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0664 - acc: 0.9789\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0676 - acc: 0.9778\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0649 - acc: 0.9796\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0654 - acc: 0.9786\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0747 - acc: 0.9764\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0661 - acc: 0.9787\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0630 - acc: 0.9800\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0657 - acc: 0.9792\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0657 - acc: 0.9794\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0636 - acc: 0.9794\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0634 - acc: 0.9797\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0637 - acc: 0.9794\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0631 - acc: 0.9799\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0631 - acc: 0.9798\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0611 - acc: 0.9806\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0626 - acc: 0.9797\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0604 - acc: 0.9806\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0622 - acc: 0.9798\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0612 - acc: 0.9808\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0589 - acc: 0.9811\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0597 - acc: 0.9813\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0622 - acc: 0.9803\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0631 - acc: 0.9797\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0599 - acc: 0.9809\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0577 - acc: 0.9812\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0605 - acc: 0.9812\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0586 - acc: 0.9818\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0616 - acc: 0.9807\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0621 - acc: 0.9805\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0565 - acc: 0.9824\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0583 - acc: 0.9819\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0598 - acc: 0.9812\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0579 - acc: 0.9814\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0593 - acc: 0.9817\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0603 - acc: 0.9813\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0581 - acc: 0.9817\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0568 - acc: 0.9820\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0559 - acc: 0.9829\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0566 - acc: 0.9824\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0579 - acc: 0.9821\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0562 - acc: 0.9820\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0560 - acc: 0.9827\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0577 - acc: 0.9816\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0552 - acc: 0.9827\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0593 - acc: 0.9818\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0561 - acc: 0.9826\n",
      "[[2424    0   17    2   57]\n",
      " [   0 2489    3    8    0]\n",
      " [  36    1 2413   17   33]\n",
      " [   3    6   16 2466    9]\n",
      " [  42    0   15    7 2436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2500\n",
      "           1       1.00      1.00      1.00      2500\n",
      "           2       0.98      0.97      0.97      2500\n",
      "           3       0.99      0.99      0.99      2500\n",
      "           4       0.96      0.97      0.97      2500\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     12500\n",
      "   macro avg       0.98      0.98      0.98     12500\n",
      "weighted avg       0.98      0.98      0.98     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropout 使用的限制 https://stats.stackexchange.com/questions/299292/dropout-makes-performance-worse\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=14, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 在這裡，你可以嘗試增減 epochs 和 batch_size\n",
    "#model.fit(X_train , dummy_npy, epochs=200, batch_size=5000, verbose=1, shuffle=True)\n",
    "model.fit(X_train, dummy_npy,\n",
    "          batch_size=200,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          shuffle=True)\n",
    "\n",
    "predicty = model.predict(testX)\n",
    "predicty = encoder.inverse_transform([np.argmax(item) for item in predicty])\n",
    "print(confusion_matrix(testy,predicty))\n",
    "print(classification_report(testy,predicty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
